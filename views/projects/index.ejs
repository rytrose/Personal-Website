<div class="container">
    <div class="row projects">
        <div class="col-sm-3">
            <h2>Projects</h2>
            <ul class="nav nav-pills nav-stacked">
                <li class="nav-item active"><a href="#tab1" data-toggle="tab">The Social Composition Project</a></li>
                <li class="nav-item"><a href="#tab2" data-toggle="tab">Interactive Recital (POC)</a></li>
            </ul>
        </div>
        
        <div class="col-xs-9">
            <div class="tab-content padRight">
                <div class="tab-pane fade in active" id="tab1">
                    <h1 class="text-center">The Social Composition Project</h1>
                    <p>
                        This project seeks to interpret the human interactions exhibited through social media into music 
                        by procedurally generating a musical composition using a Facebook post as input. The
                        composition is based off of the Facebook Reactions (i.e. Like, Love, Wow, etc.) associated with
                        the input post. Each reaction has an associated melodic phrase which floats over an oscillating
                        drone. A disproportionate amount of Like reactions led to the inclusion of an additional phrase
                        representing a sequence of uninterrupted Likes.
                    </p>
                    <p>
                        The inspiration for this project came from observing Facebook interactions following the tragic 
                        massacre at the Pulse Orlando nightclub on June 12th, 2016. Many of my peers posted heartfelt and
                        sensitive messages on Facebook in response to the tragedy, and many of these posts had emotionally-charged discussions
                        in the comments section. One particular discussion was over the insensitivity of reacting to a 
                        memorial/grieving post with a Wow reaction. Observing this phenomenon and the ensuing debate led me to
                        observe a particular significance to these digital reactions. My initial reaction was to apply the 
                        concept of a reaction-generated composition to the Pulse Orlando Facebook page. However, transforming a specific
                        post proved much more effective and feasible, which led to the current iteration that allows users of
                        the project generate compositions from posts on their own timeline.
                    </p>
                    <p>
                        The project utilizes <a class="projA" href="https://developers.facebook.com/docs/graph-api" target="_blank" >Facebook's Graph API</a> 
                        for data collection, the <a class="projA" href="https://www.w3.org/TR/webaudio/" target="_blank" >W3C Web Audio API</a> 
                        for sequencing, and <a class="projA" href="https://github.com/tjoen/three.js" target="_blank" >THREE.js</a> and the CSS3D renderer 
                        for visualization. Code for this project can be found <a class="projA" href="https://github.com/rytrose/Personal-Website/tree/master/assets/scp" target="_blank" >here</a>.
                    </p>
                    <div class="text-center"><a class="btn btn-default" href="/projects/scp">see the project</a></div>
                </div>
                <div class="tab-pane fade" id="tab2">
                    <h1 class="text-center">Interactive Recital (POC)</h1>
                    <p>
                        This project idea stems from my desire to increase the accessibility and attractiveness of classical
                        music through the use of technology. My idea is to play an arrangement of Hector Berlioz's <i>Harold en Italie</i> 
                        on alto saxophone as the solo instrument, accompanied by an orchestral backing track and augmented by 
                        audience-chosen audio effects. While listening to viola music I stumbled across <i>Harold en Italie</i> and
                        immediately wished to arrange a version for alto saxophone, which has a similar range as a viola. To perfom
                        this piece, however, I would need an orchestra -- so I began using a software called PhotoScore to create
                        a backing track using Finale's Garritan instruments to provide a rudimentary accompaniment 
                        (with more resources at my disposal I would like to create a backing track with significantly more musical sensitivity).
                    </p>
                    <p>
                        Able to provide accompaniment for myself I then began to think about audience engagement and interaction. 
                        While reading about the piece and about Berlioz's compositional philosophy, I learned that Berlioz sought to
                        integrate non-musical or real sounds into his pieces, an example of which is the unpitched bells in his
                        <i>Symphonie Fantastique</i>. I think a lot about how the non-musical world can be interpreted musically and
                        thought to tastefully incorporate personally recorded sounds into my arrangement of <i>Harold en Italie</i>. 
                        In order to give the audience some investment in the piece, I will provide options of various recorded sounds
                        to inject into the real-time performance of my piece to the audience, who will choose these sounds via a 
                        smartphone web application. Their choices will be polled at predetermined intervals in the piece, and the results 
                        of these polls will determine which sounds get introduced at moments I have chosen.
                    </p>
                    <p>
                        I will use a real-time database service such as Google's Firebase to collect polling information while I am 
                        playing. I also read about a way to control the sequencing software Ableton Live through <a class="projA" href="http://remotescripts.blogspot.com/2010/03/introduction-to-framework-classes.html?m=1" target="_blank" >Python-emulated MIDI instruments</a>,
                        which will allow my backing track to react and respond to the polling results automatically while I play. I 
                        believe the audience's interaction and role in creating the music will provide a more engaging
                        and fulfilling experience than otherwise listening to the piece statically in a concert hall.
                    </p>
                    
                </div>
            </div>
        </div>
    </div>
</div>